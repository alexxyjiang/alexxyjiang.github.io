{"componentChunkName":"component---src-templates-tag-template-tag-template-tsx","path":"/tag/machine-learning/page/1/","result":{"data":{"site":{"siteMetadata":{"title":"Blog by Alex Jiang","subtitle":"Alex Jiang's personal blog built by Gatsby"}},"allMarkdownRemark":{"edges":[{"node":{"fields":{"slug":"/posts/2016-03-08---My-Understanding-of-Knowledge-Distilling//posts/my-understanding-of-knowledge-distilling","categorySlug":"/category/machine-learning/"},"frontmatter":{"title":"My Understanding of Knowledge Distilling","date":"2016-03-08T10:15:00.000Z","category":"Machine Learning","description":"knowledge distilling is a method to compress a large model into a smaller one.","slug":"/posts/my-understanding-of-knowledge-distilling"}}},{"node":{"fields":{"slug":"/posts/2015-06-25---The-Expectation-Maximization-Algorithm//posts/the-expectation-maximization-algorithm","categorySlug":"/category/machine-learning/"},"frontmatter":{"title":"The Expectation Maximization Algorithm","date":"2015-06-25T19:00:00.000Z","category":"Machine Learning","description":"an introduction to the Expectation Maximization algorithm.","slug":"/posts/the-expectation-maximization-algorithm"}}},{"node":{"fields":{"slug":"/posts/2014-09-18---My-Understanding-of-Word2Vec//posts/my-understanding-of-word2vec","categorySlug":"/category/machine-learning/"},"frontmatter":{"title":"My Understanding of Word2Vec","date":"2014-09-18T10:00:00.000Z","category":"Machine Learning","description":"word2vec is a classic model for generating word embeddings, it's important to understand how it works.","slug":"/posts/my-understanding-of-word2vec"}}}]}},"pageContext":{"group":"Machine Learning","limit":5,"offset":5,"pagination":{"currentPage":1,"prevPagePath":"/tag/machine-learning","nextPagePath":"/tag/machine-learning/page/2","hasNextPage":false,"hasPrevPage":true}}},"staticQueryHashes":["251939775","288581551","401334301","63107425"],"slicesMap":{}}